# BigDataPipeline

## Goal:

1.  Learn how to use Databricks environment
    1.  Create cluster
    2.  Switch on DBFS (Databricks file system)
    3.  Upload required CSV, Parquet files
    4.  Create Delta Table
2.   Understanding Low level Design (LLD) of working good codebase in Data engineering
    1.  Understand Factory pattern
    2.  Create one abstract reader which will use factory pattern
3.  Designing code box
    1.  Required Extractor, Transformer and loader class
    2.  Required utils class
4.  Spark Concept
    1.  Spark session
    2.  Row vs Column FIle formats
    3.  Broadcast join
    4.  Narrow vs Wide Transformation
    5.  Job stage & Task
